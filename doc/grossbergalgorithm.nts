grossbergalgorithim.nts
(Thagard's method of calculating Grossberg updating of activation
values, in network.lisp, is confusing.  Here are notes about what
really has to be done, oriented toward the possibility of doing it
with matrices.  This is based on my description of the method in
"Moderate Role", which was based on rereading H&T1989 and rereading
Thagard's code.  Doing it according to the steps given here might not
be what's most efficient, and it may not useful to give all of the
intermediate data structures names in the ultimate code.)

For each person, there are two networks: the analogy network and the
proposition network.  The following applies to each of the two
networks in each of the persons.

0. Initial data structures:

	Activns: An Nx1 column vector of activations (current state of
	nodes), where N is the number of node in this network.
	Activations range from -1 to 1.

	Weights: An NxN matrix of weights, representing links between
	nodes.  These range from -1 to 1.  Many will be zero,
	representing no link.  Old activations correspond to column
	indexes.  New activations correspond to row indexes.  [The flow
	of information is from right to left.]  The nonzero weights in
	row r represent the weights of links from nodes linked to the
	node represented by r.

	Note: There is a drawback to treating such a matrix as the basic
	representation of links.  I have had cases in which a link had
	zero weight (usually in the proposition network).  That it's
	treated identically to non-links in the activation calculations
	is OK, but for graphical representaions of networks, this is
	undesirable--confusing.  Links will be missing where they should
	be, and can pop in and out of existence in the graphical
	display.  There should be a way of showing links that don't
	(yet) have a nonzero activation.  Thus I should probably have a
	separate representation of the network available for graphical
	display or other analyses, e.g.  analyses of community or
	neighborhood network structure.  This alternative representation
	could be a matrix of 1's and 0's, or just a list-like structure.

	Or maybe there's something I could do where non-links are
	represented by nil or NaN or something.  Or some number that's
	way too large or something.

	Note: NaN and Infinity, as names, don't function as normal
	symbols, but they exist, and you can set them into matrix
	elements in both Clatrix (using clatrix.core/set) and Vectorz
	(using mset!).

	(/ 1.0 0.0) => Infinity [(/ 1 0) generates an error].  You can
	then get NaN by dividing Infinity by Infinity.  These entities
	behave as you'd expect, with Infinity propagating through
	multiplication and addition, and returning -Infinity when
	multiplied by a negative number.  NaN is utterly infectious, as
	you'd expect.  Infinity and Infinity are numerically equal (==)
	and generally equal (=).  NaN and NaN are numerically not equal
	(==), since, I guess, that's just the nature of NaN-ness.  It is
	possible for it NaN = NaN [i.e. the more general equality] but
	only if they are the same NaN object.  Apparently there can be
	more than one.  If you divide infinity by infinity more than
	once, you get different NaN objects.  (This NaN behavior does
	not sound like something that should be depended on in the
	future.  Testing for equality with Infinity seems more reliable.
	Um, on the other hand, what I really want is something that
	behaves like zero when you sum it.  Not something that will
	infect the whole sum.  Hmm--what about 0 vs 0.0?  
	0 == 0.0, but they aren't = .  Well, that's risky.  Asking for
	errors.  Since in most cases, floats will infect integers.
	Don't do that.  Probably just need another matrix that
	distinguishes real links from non-links.)

Notes/comments are indented.  Steps are numbered at the left margin.

	Negative activations are not transmitted.  They might as well be
	zero. So:

1. Apply max(0,a_ij) to Activns.  The result PosActivns is a vector of
activations in which the negative activations have been turned into
zeros.

	New activations are a function of the weighted sums of positive
	activations of linked nodes.  An early step is to create such sums.
	However, we actually need two vectors of sums, or a 2xN
	matrix, or something.  We have to distinguish sums that have
	their source in positive links, and sums that have their
	source in negative links.  The reason is that when we scale
	the effect of incoming activations (i.e. the sum) by
	distance from the extremes [-1, 1], we have to scale in
	different directions depending on whether the sum comes from
	positively-weighted or negatively-weighted links. But that
	information about the source is lost in the sum itself.  So we
	need two sums.

2. From Weights, create two matrices PosWeights and NegWeights,
containing only nonnegative and nonpositive weights, respectively. 
Each can have zeros where the weights aren't positive or aren't
negative, respectively.  

	NOTE: These last matrices can just be created once at the
	beginning of the run in the analogy networks *if* everyone
	starts with all of the propositions.  In that case, the analogy
	network structure and weights will not change.  The proposition
	network weights readily change over time, however, so we've got
	to split out PosWeights and NegWeights every time, potentially.
	Maybe there should be a switch to set whether to allow the
	analogy PosWeights and NegWeights to be fixed at the beginning.
	An alternative is to leave them fixed but allow introduction of
	new propositions to cause them to be updated.  Note however that
	in a naive implementation, what we're doing is recreating what
	could be a 100,000 element matrix, for example.

	Maybe there should simply not be a combined weight matrix at
	all.  Just start with two of them.  And then when you update
	them in the proposition network, or in the analogy network when
	new propositions are introduced, you have to keep track so that
	when a weight flips sign, you zero out the one matrix and update
	to a nonzero element in the other.  (Possibly it could be
	simpler [faster??] to use positive values in NegWeights, and
	then just multiply by 1 at an appropriate step.)

	NOTE that the sums from both positively and negatively
	weighted links will always be positive, and negative,
	respectively, because we ignore negative activations in
	computing inputs.

	Note the effect of the separate scaling by distance from
	extremes is that when the old activation is near 1, positive
	links have a small effect, but negative links have a large
	effect, since they are scaled by distance from -1 (see below).
	And vice versa when the old activation is near -1.

3. Multiply PosWeights X Activns to produce PosWtdInputs, and NegWeights
X Activns to produce NegWtdSums.  Each of these new structures is a
vector of values, positive, negative, or zero.  These are not yet the
new activations. The new activations will be a function of these values
[p_i and n_i in "Moderate Role", p. 13].

4. Calculate two vectors of distances of old activations from the
extremes.  
DistsFromMin = Actvns - (-1) = Activns + 1 [which may be > 1 for some]
DistsFromMax = 1 - Actvns [which may be < -1 for some]
	(Really?  This seems wrong.  It is what's in H&T1989.
	And it's in network.lisp.)
Actually, there's another step of clipping to the extremes.  If we do
that all in one step, it goes like this:
ClippedDistsFromMin = min(Activns + 1, 1)
ClippedDistsFromMax = max(1 - Actvns, -1)

	clojure notes:
		(clatrix.core/map (fn [e] (max e 0)) M) ; clips above zero
		(clatrix.core/map (fn [e] (min e 0)) M) ; clips below zero
		; here's how you're supposed to do it:
		(clojure.core.matrix.protocols/element-map 
		   M (fn [e] (max e 0))))
		   ; does the right thing in Vectorz
		   ; returns a LazySeq in Clatrix. you have redo shape
	NO USE EMAP.

	There is a decay on the contribution of each old activation to
	the new activation of the same node.

	ACK! There's an error in the description of the algorithim in
	"Moderate Role"!  I can't belief this.  There the
	constribution of the old activation to the new activation is:
		old * .1 + old * .99 = old * 1.09
	but what it should be is
		old * (.99 - .1) = old * .89
	cf. H&T1989 p. 313.  And actually, in the code, now 10/2013,
	at least, what it's actually doing is
		old * (1 - .1) = old * .90

5. Multiply Activns by the decay value .9 = 1 - .1 = 1 - decay amount 
[*decay-amount* in POPCO] to produce the result vector DKdActivns.

6.
NEXT: Scale the sums in WtdSums by |max/min - current activn|, which
depends on whether the weights for the sum were negative or positive.
Then add the results to DKdActivns to get the new activation vector.
